{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifted log-scale\n",
    "In this notebook we perform the estimation with parameters on a shifted log-scale $\\log_{10}(\\epsilon+x)$, where $\\epsilon$ is the shift parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "import amici\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import petab \n",
    "\n",
    "import pypesto\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.petab\n",
    "import pypesto.visualize as visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model import\n",
    "Since there is no build-in version for parameters on the shifted scale, we import the petab model with parameters specified to be linear and then later transform them by hand. The only thing that changes in this petab model is the nominal value of the parameters, which is the transform of the nominal value in the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= \"Spoegler_conversionReaction\"\n",
    "param_scale= \"log10_shift\"\n",
    "\n",
    "\n",
    "# the yaml file includes all important links to other files\n",
    "yaml_config =\"petab/\"+param_scale+\"/\"+model_name+\".yaml\"\n",
    "# create a petab problem\n",
    "petab_problem = petab.Problem.from_yaml(yaml_config)\n",
    "\n",
    "# or create from folder (did not work)\n",
    "# petab_problem = petab.Problem.from_folder(\"petab/\"+param_scale)\n",
    "\n",
    "# import to amici\n",
    "importer = pypesto.petab.PetabImporter(petab_problem)\n",
    "importer.compile_model()\n",
    "\n",
    "model = importer.create_model()\n",
    "\n",
    "# model properties\n",
    "print(\"Model parameters:\", list(model.getParameterIds()), \"\\n\")\n",
    "print(\"Model constant parameters:\", list(model.getFixedParameterIds()), \"\\n\")\n",
    "print(\"Model outputs:    \", list(model.getObservableIds()), \"\\n\")\n",
    "print(\"Model states:     \", list(model.getStateIds()), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize solver and options\n",
    "solver = importer.create_solver(model)\n",
    "\n",
    "# enable sensitivities\n",
    "solver.setSensitivityOrder(amici.SensitivityOrder_first)       \n",
    "solver.setSensitivityMethod(amici.SensitivityMethod_forward)  \n",
    "model.requireSensitivitiesForAllParameters()                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create objective function\n",
    "In the next part we first create an objective function out of the model. This function takes parameters as if they were on a linear scale, since we specified it this way in the PEtab problem.\n",
    "In order to get an objective function that can take parameters on the shifted scale, we concatenate the linear objective function with the inverse of the parameter transformation.\n",
    "And for the gradient we use: $(f'(x))^{-1}=\\frac{1}{f'(x)}$ for bijective functions.\n",
    "So with the input being: $x=f(y)=log_{10}(\\epsilon+y)$\n",
    "We get $obj(x)=obj.lin(f^{-1}(x))$ as the new objective function and $obj'(x)=obj.lin'(f^{-1}(x))*10^x*ln(10)$ as the new derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing amici model in folder /home/vinc777/python_projects/moses/spoegler_model_reduction/amici_models/Sp_gler_ConversionReaction.\n"
     ]
    }
   ],
   "source": [
    "# linear objective function\n",
    "obj_lin = importer.create_objective()\n",
    "\n",
    "# shifted parameter\n",
    "eps = 1\n",
    "def fun(x):\n",
    "    return obj_lin.get_fval(10**np.array(x)-eps)\n",
    "\n",
    "def grad(x):\n",
    "    return obj_lin.get_grad(10**np.array(x)-eps) * 10**np.array(x) * np.log(10)\n",
    "\n",
    "\n",
    "# new objective function\n",
    "obj = pypesto.Objective(fun=fun, grad=grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the obj_lin is different from the objective function in the linear-scale case. This is suspicious and should normally not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal x =  [0.07918125, 0.04139269, 0.0, 0.17609126]\n",
      "optimal lh value 1.5753096950853929\n"
     ]
    }
   ],
   "source": [
    "print('optimal x = ', petab_problem.x_nominal)\n",
    "print('optimal lh value', obj(petab_problem.x_nominal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at this later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gradient\n",
    "# test_opt = obj.check_grad(petab_problem.x_nominal)\n",
    "# print(test_opt[np.array(['grad', 'fd_c', 'abs_err', 'rel_err'])])\n",
    "# test_1 = obj.check_grad([1,1,1,1])\n",
    "# print(test_1[np.array(['grad', 'fd_c', 'abs_err', 'rel_err'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer object\n",
    "optimizer = optimize.ScipyOptimizer()\n",
    "\n",
    "# create problem object\n",
    "problem = importer.create_problem(obj)\n",
    "\n",
    "# do the optimization\n",
    "n_starts = 100\n",
    "\n",
    "result = optimize.minimize(\n",
    "        problem=problem, optimizer=optimizer, n_starts=n_starts, filename=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "best_result=result.optimize_result.as_list(\"x\")[0][\"x\"]\n",
    "print('best parameter: ', best_result)\n",
    "print('best likelihood value: ', problem.objective(best_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waterfall plot\n",
    "fvals = result.optimize_result.get_for_key(\"fval\")\n",
    "fval = np.array(fvals)\n",
    "fval=fval[fval < 1e2]\n",
    "visualize.waterfall_lowlevel(fval, scale_y='lin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converged means close to the best result up to a threshold\n",
    "\n",
    "threshold = 1e-2\n",
    "n_compares = len(result.optimize_result.as_list(\"x\"))\n",
    "n_converged = 0\n",
    "for i in range(0, n_compares):\n",
    "    compare_result = result.optimize_result.as_list(\"x\")[i][\"x\"]\n",
    "    converged = (np.abs((compare_result - best_result)) < (threshold * len(compare_result))).all()\n",
    "    if converged:\n",
    "        n_converged += 1\n",
    "\n",
    "print(\"Number of converged runs: \", n_converged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parameters(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startpoints = result.optimize_result.get_for_key('x0')\n",
    "# print (startpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =   [['theta1', petab_problem.x_nominal[0], best_result[0], 0.2, 10**best_result[0]-1, obj(petab_problem.x_nominal), obj(best_result)],\n",
    "             ['theta2', petab_problem.x_nominal[1], best_result[1], 0.1, 10**best_result[1]-1, obj(petab_problem.x_nominal), obj(best_result)],\n",
    "             ['theta3', petab_problem.x_nominal[2], best_result[2], 0.0, 10**best_result[2]-1, obj(petab_problem.x_nominal), obj(best_result)],\n",
    "             ['sigma', petab_problem.x_nominal[3], best_result[3], 0.15, 10**best_result[3]-1, obj(petab_problem.x_nominal), obj(best_result)]]\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Parameter', 'Nominal', 'best', 'nominal-linear', 'best-linear', 'nominal-likelihood', 'likelihood'])\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(\"estimation_results/\"+param_scale+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
